# Interpretability-Techniques

## Intro

Machine learning has significantly advanced data science by helping to achieve superior model performance. However, it comes at the cost of complexity and interpretability. Therefore, interpretability techniques are required to offset this increase in complexity. In this project, we analyze five interpretability techniques and assessing their respective advantages and disadvantages. To do this, we first fit a random forest regression model on housing data from King County from 2014-2015. Afterwords, we utilitze techniques such as feature importance plots, partial dependence plots, individual conditional expectations, global/local surrogate, and Shapley value to intperpet the model.

## How to run

1. Clone the repository
2. Open the Interpretability_Techniques_Notebook.ipynb file 
3. Ensure all appropiate libraries and dependencies are installed
4. Run each code chunks sequentially

All plots generated from the notebook are saved in the Plots folder.



